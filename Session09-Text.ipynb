{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = 'Do you like green eggs and ham?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', 'you', 'like', 'green', 'eggs', 'and', 'ham']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.lower().strip('?').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'and', u'do', u'eggs', u'green', u'ham', u'like', u'you']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x7 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform([sentence]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = ['Do you like green eggs and ham?',\n",
    "        'I do not like them, Sam-I-am.',\n",
    "       'I do not like green eggs and ham.',\n",
    "       'Not in a box. Not with a fox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'am',\n",
       " u'and',\n",
       " u'box',\n",
       " u'do',\n",
       " u'eggs',\n",
       " u'fox',\n",
       " u'green',\n",
       " u'ham',\n",
       " u'in',\n",
       " u'like',\n",
       " u'not',\n",
       " u'sam',\n",
       " u'them',\n",
       " u'with',\n",
       " u'you']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = pd.DataFrame(vectorizer.transform(text).toarray(),\n",
    "                    columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am</th>\n",
       "      <th>and</th>\n",
       "      <th>box</th>\n",
       "      <th>do</th>\n",
       "      <th>eggs</th>\n",
       "      <th>fox</th>\n",
       "      <th>green</th>\n",
       "      <th>ham</th>\n",
       "      <th>in</th>\n",
       "      <th>like</th>\n",
       "      <th>not</th>\n",
       "      <th>sam</th>\n",
       "      <th>them</th>\n",
       "      <th>with</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   am  and  box  do  eggs  fox  green  ham  in  like  not  sam  them  with  \\\n",
       "0   0    1    0   1     1    0      1    1   0     1    0    0     0     0   \n",
       "1   1    0    0   1     0    0      0    0   0     1    1    1     1     0   \n",
       "2   0    1    0   1     1    0      1    1   0     1    1    0     0     0   \n",
       "3   0    0    1   0     0    1      0    0   1     0    2    0     0     1   \n",
       "\n",
       "   you  \n",
       "0    1  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words['text'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am</th>\n",
       "      <th>and</th>\n",
       "      <th>box</th>\n",
       "      <th>do</th>\n",
       "      <th>eggs</th>\n",
       "      <th>fox</th>\n",
       "      <th>green</th>\n",
       "      <th>ham</th>\n",
       "      <th>in</th>\n",
       "      <th>like</th>\n",
       "      <th>not</th>\n",
       "      <th>sam</th>\n",
       "      <th>them</th>\n",
       "      <th>with</th>\n",
       "      <th>you</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Do you like green eggs and ham?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I do not like them, Sam-I-am.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I do not like green eggs and ham.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in a box. Not with a fox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   am  and  box  do  eggs  fox  green  ham  in  like  not  sam  them  with  \\\n",
       "0   0    1    0   1     1    0      1    1   0     1    0    0     0     0   \n",
       "1   1    0    0   1     0    0      0    0   0     1    1    1     1     0   \n",
       "2   0    1    0   1     1    0      1    1   0     1    1    0     0     0   \n",
       "3   0    0    1   0     0    1      0    0   1     0    2    0     0     1   \n",
       "\n",
       "   you                               text  \n",
       "0    1    Do you like green eggs and ham?  \n",
       "1    0      I do not like them, Sam-I-am.  \n",
       "2    0  I do not like green eggs and ham.  \n",
       "3    0       Not in a box. Not with a fox  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorizer.fit(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'am',\n",
       " u'and',\n",
       " u'and ham',\n",
       " u'box',\n",
       " u'box not',\n",
       " u'do',\n",
       " u'do not',\n",
       " u'do you',\n",
       " u'eggs',\n",
       " u'eggs and',\n",
       " u'fox',\n",
       " u'green',\n",
       " u'green eggs',\n",
       " u'ham',\n",
       " u'in',\n",
       " u'in box',\n",
       " u'like',\n",
       " u'like green',\n",
       " u'like them',\n",
       " u'not',\n",
       " u'not in',\n",
       " u'not like',\n",
       " u'not with',\n",
       " u'sam',\n",
       " u'sam am',\n",
       " u'them',\n",
       " u'them sam',\n",
       " u'with',\n",
       " u'with fox',\n",
       " u'you',\n",
       " u'you like']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigs = pd.DataFrame(bigram_vectorizer.transform(text).toarray(),\n",
    "                    columns = bigram_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am</th>\n",
       "      <th>and</th>\n",
       "      <th>and ham</th>\n",
       "      <th>box</th>\n",
       "      <th>box not</th>\n",
       "      <th>do</th>\n",
       "      <th>do not</th>\n",
       "      <th>do you</th>\n",
       "      <th>eggs</th>\n",
       "      <th>eggs and</th>\n",
       "      <th>...</th>\n",
       "      <th>not like</th>\n",
       "      <th>not with</th>\n",
       "      <th>sam</th>\n",
       "      <th>sam am</th>\n",
       "      <th>them</th>\n",
       "      <th>them sam</th>\n",
       "      <th>with</th>\n",
       "      <th>with fox</th>\n",
       "      <th>you</th>\n",
       "      <th>you like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   am  and  and ham  box  box not  do  do not  do you  eggs  eggs and  \\\n",
       "0   0    1        1    0        0   1       0       1     1         1   \n",
       "1   1    0        0    0        0   1       1       0     0         0   \n",
       "2   0    1        1    0        0   1       1       0     1         1   \n",
       "3   0    0        0    1        1   0       0       0     0         0   \n",
       "\n",
       "     ...     not like  not with  sam  sam am  them  them sam  with  with fox  \\\n",
       "0    ...            0         0    0       0     0         0     0         0   \n",
       "1    ...            1         0    1       1     1         1     0         0   \n",
       "2    ...            1         0    0       0     0         0     0         0   \n",
       "3    ...            0         1    0       0     0         0     1         1   \n",
       "\n",
       "   you  you like  \n",
       "0    1         1  \n",
       "1    0         0  \n",
       "2    0         0  \n",
       "3    0         0  \n",
       "\n",
       "[4 rows x 31 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorizer.set_params(min_df = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorizer.fit(text)\n",
    "len(bigram_vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>and ham</th>\n",
       "      <th>do</th>\n",
       "      <th>do not</th>\n",
       "      <th>eggs</th>\n",
       "      <th>eggs and</th>\n",
       "      <th>green</th>\n",
       "      <th>green eggs</th>\n",
       "      <th>ham</th>\n",
       "      <th>like</th>\n",
       "      <th>like green</th>\n",
       "      <th>not</th>\n",
       "      <th>not like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  and ham  do  do not  eggs  eggs and  green  green eggs  ham  like  \\\n",
       "0    1        1   1       0     1         1      1           1    1     1   \n",
       "1    0        0   1       1     0         0      0           0    0     1   \n",
       "2    1        1   1       1     1         1      1           1    1     1   \n",
       "3    0        0   0       0     0         0      0           0    0     0   \n",
       "\n",
       "   like green  not  not like  \n",
       "0           1    0         0  \n",
       "1           0    1         1  \n",
       "2           1    1         1  \n",
       "3           0    2         0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigs = pd.DataFrame(bigram_vectorizer.transform(text).toarray(),\n",
    "                    columns = bigram_vectorizer.get_feature_names())\n",
    "bigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.38  0.    0.31  0.38  0.    0.38  0.38  0.    0.31  0.    0.    0.\n",
      "   0.    0.48]\n",
      " [ 0.49  0.    0.    0.31  0.    0.    0.    0.    0.    0.31  0.31  0.49\n",
      "   0.49  0.    0.  ]\n",
      " [ 0.    0.41  0.    0.33  0.41  0.    0.41  0.41  0.    0.33  0.33  0.    0.\n",
      "   0.    0.  ]\n",
      " [ 0.    0.    0.42  0.    0.    0.42  0.    0.    0.42  0.    0.54  0.    0.\n",
      "   0.42  0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.transform(text).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'end', u'fire', u'ice', u'in', u'say', u'some', u'the', u'will', u'world']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = pd.DataFrame(tfidf_vectorizer.transform(text).toarray(),\n",
    "                    columns = tfidf_vectorizer.get_feature_names())\n",
    "words['text'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df = 2,\n",
    "                                   max_df = .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>do</th>\n",
       "      <th>eggs</th>\n",
       "      <th>green</th>\n",
       "      <th>ham</th>\n",
       "      <th>like</th>\n",
       "      <th>not</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.433928</td>\n",
       "      <td>0.351302</td>\n",
       "      <td>0.433928</td>\n",
       "      <td>0.433928</td>\n",
       "      <td>0.433928</td>\n",
       "      <td>0.351302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Do you like green eggs and ham?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>I do not like them, Sam-I-am.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.409400</td>\n",
       "      <td>0.331445</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>0.331445</td>\n",
       "      <td>0.331445</td>\n",
       "      <td>I do not like green eggs and ham.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Not in a box. Not with a fox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and        do      eggs     green       ham      like       not  \\\n",
       "0  0.433928  0.351302  0.433928  0.433928  0.433928  0.351302  0.000000   \n",
       "1  0.000000  0.577350  0.000000  0.000000  0.000000  0.577350  0.577350   \n",
       "2  0.409400  0.331445  0.409400  0.409400  0.409400  0.331445  0.331445   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  1.000000   \n",
       "\n",
       "                                text  \n",
       "0    Do you like green eggs and ham?  \n",
       "1      I do not like them, Sam-I-am.  \n",
       "2  I do not like green eggs and ham.  \n",
       "3       Not in a box. Not with a fox  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.fit(text)\n",
    "\n",
    "words = pd.DataFrame(tfidf_vectorizer.transform(text).toarray(),\n",
    "                    columns = tfidf_vectorizer.get_feature_names())\n",
    "words['text'] = text\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eggs</th>\n",
       "      <th>green</th>\n",
       "      <th>ham</th>\n",
       "      <th>like</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.523035</td>\n",
       "      <td>0.523035</td>\n",
       "      <td>0.523035</td>\n",
       "      <td>0.423442</td>\n",
       "      <td>Do you like green eggs and ham?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>I do not like them, Sam-I-am.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523035</td>\n",
       "      <td>0.523035</td>\n",
       "      <td>0.523035</td>\n",
       "      <td>0.423442</td>\n",
       "      <td>I do not like green eggs and ham.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Not in a box. Not with a fox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eggs     green       ham      like                               text\n",
       "0  0.523035  0.523035  0.523035  0.423442    Do you like green eggs and ham?\n",
       "1  0.000000  0.000000  0.000000  1.000000      I do not like them, Sam-I-am.\n",
       "2  0.523035  0.523035  0.523035  0.423442  I do not like green eggs and ham.\n",
       "3  0.000000  0.000000  0.000000  0.000000       Not in a box. Not with a fox"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.set_params(stop_words = 'english')\n",
    "\n",
    "tfidf_vectorizer.fit(text)\n",
    "\n",
    "words = pd.DataFrame(tfidf_vectorizer.transform(text).toarray(),\n",
    "                    columns = tfidf_vectorizer.get_feature_names())\n",
    "words['text'] = text\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'not in a box not with a fox'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def quick_stemmer(sentence):\n",
    "    s = sentence.lower()\n",
    "    s = s.split()\n",
    "    s = [w.strip(punctuation) for w in s]\n",
    "    s = [stemmer.stem(w) for w in s]\n",
    "    return ' '.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'man trap in texa cash machin send help me note'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_stemmer(\"Man trapped in Texas cash machine sends 'help me' notes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "words['stemmed'] = words['text'].apply(quick_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eggs</th>\n",
       "      <th>green</th>\n",
       "      <th>ham</th>\n",
       "      <th>like</th>\n",
       "      <th>text</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.523035</td>\n",
       "      <td>0.523035</td>\n",
       "      <td>0.523035</td>\n",
       "      <td>0.423442</td>\n",
       "      <td>Do you like green eggs and ham?</td>\n",
       "      <td>do you like green egg and ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>I do not like them, Sam-I-am.</td>\n",
       "      <td>i do not like them sam-i-am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523035</td>\n",
       "      <td>0.523035</td>\n",
       "      <td>0.523035</td>\n",
       "      <td>0.423442</td>\n",
       "      <td>I do not like green eggs and ham.</td>\n",
       "      <td>i do not like green egg and ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Not in a box. Not with a fox</td>\n",
       "      <td>not in a box not with a fox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eggs     green       ham      like                               text  \\\n",
       "0  0.523035  0.523035  0.523035  0.423442    Do you like green eggs and ham?   \n",
       "1  0.000000  0.000000  0.000000  1.000000      I do not like them, Sam-I-am.   \n",
       "2  0.523035  0.523035  0.523035  0.423442  I do not like green eggs and ham.   \n",
       "3  0.000000  0.000000  0.000000  0.000000       Not in a box. Not with a fox   \n",
       "\n",
       "                           stemmed  \n",
       "0    do you like green egg and ham  \n",
       "1      i do not like them sam-i-am  \n",
       "2  i do not like green egg and ham  \n",
       "3      not in a box not with a fox  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', \n",
    "              'talk.religion.misc', \n",
    "              ]\n",
    "\n",
    "newsgroups = fetch_20newsgroups(categories=categories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'talk.religion.misc']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'alt.atheism',\n",
       " 'alt.atheism',\n",
       " 'talk.religion.misc',\n",
       " 'talk.religion.misc',\n",
       " 'alt.atheism',\n",
       " 'alt.atheism',\n",
       " 'talk.religion.misc',\n",
       " 'alt.atheism',\n",
       " 'alt.atheism']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = [newsgroups.target_names[i] for i in newsgroups.target]\n",
    "target_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u' howland.reston.ans.net!europa.eng.gtefsd.com!uunet!mcsun!Germany.EU.net!news.dfn.de!tubsibr!dbstu1.rz.tu-bs.de!I3150101\\nSubject: Re: Gospel Dating\\nFrom: I3150101@dbstu1.rz.tu-bs.de (Benedikt Rosenau)\\nOrganization: Technical University Braunschweig, Germany\\nLines: 35\\n\\nIn article <66015@mimsy.umd.edu>\\nmangoe@cs.umd.edu (Charley Wingate) writes:\\n \\n(Deletion)\\n>I cannot see any evidence for the V. B. which the cynics in this group would\\n>ever accept.  As for the second, it is the foundation of the religion.\\n>Anyone who claims to have seen the risen Jesus (back in the 40 day period)\\n>is a believer, and therefore is discounted by those in this group; since\\n>these are all ancients anyway, one again to choose to dismiss the whole\\n>thing.  The third is as much a metaphysical relationship as anything else--\\n>even those who agree to it have argued at length over what it *means*, so\\n>again I don\\'t see how evidence is possible.\\n>\\n \\nNo cookies, Charlie. The claims that Jesus have been seen are discredited\\nas extraordinary claims that don\\'t match their evidence. In this case, it\\nis for one that the gospels cannot even agree if it was Jesus who has been\\nseen. Further, there are zillions of other spook stories, and one would\\nhardly consider others even in a religious context to be some evidence of\\na resurrection.\\n \\nThere have been more elaborate arguments made, but it looks as if they have\\nnot passed your post filtering.\\n \\n \\n>I thus interpret the \"extraordinary claims\" claim as a statement that the\\n>speaker will not accept *any* evidence on the matter.\\n \\nIt is no evidence in the strict meaning. If there was actual evidence it would\\nprobably be part of it, but the says nothing about the claims.\\n \\n \\nCharlie, I have seen Invisible Pink Unicorns!\\nBy your standards we have evidence for IPUs now.\\n   Benedikt\\n'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " howland.reston.ans.net!europa.eng.gtefsd.com!uunet!mcsun!Germany.EU.net!news.dfn.de!tubsibr!dbstu1.rz.tu-bs.de!I3150101\n",
      "Subject: Re: Gospel Dating\n",
      "From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Rosenau)\n",
      "Organization: Technical University Braunschweig, Germany\n",
      "Lines: 35\n",
      "\n",
      "In article <66015@mimsy.umd.edu>\n",
      "mangoe@cs.umd.edu (Charley Wingate) writes:\n",
      " \n",
      "(Deletion)\n",
      ">I cannot see any evidence for the V. B. which the cynics in this group would\n",
      ">ever accept.  As for the second, it is the foundation of the religion.\n",
      ">Anyone who claims to have seen the risen Jesus (back in the 40 day period)\n",
      ">is a believer, and therefore is discounted by those in this group; since\n",
      ">these are all ancients anyway, one again to choose to dismiss the whole\n",
      ">thing.  The third is as much a metaphysical relationship as anything else--\n",
      ">even those who agree to it have argued at length over what it *means*, so\n",
      ">again I don't see how evidence is possible.\n",
      ">\n",
      " \n",
      "No cookies, Charlie. The claims that Jesus have been seen are discredited\n",
      "as extraordinary claims that don't match their evidence. In this case, it\n",
      "is for one that the gospels cannot even agree if it was Jesus who has been\n",
      "seen. Further, there are zillions of other spook stories, and one would\n",
      "hardly consider others even in a religious context to be some evidence of\n",
      "a resurrection.\n",
      " \n",
      "There have been more elaborate arguments made, but it looks as if they have\n",
      "not passed your post filtering.\n",
      " \n",
      " \n",
      ">I thus interpret the \"extraordinary claims\" claim as a statement that the\n",
      ">speaker will not accept *any* evidence on the matter.\n",
      " \n",
      "It is no evidence in the strict meaning. If there was actual evidence it would\n",
      "probably be part of it, but the says nothing about the claims.\n",
      " \n",
      " \n",
      "Charlie, I have seen Invisible Pink Unicorns!\n",
      "By your standards we have evidence for IPUs now.\n",
      "   Benedikt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups.data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(target_names, newsgroups.data),\n",
    "                  columns = ['newsgroup','text'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsgroup</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>From: mangoe@cs.umd.edu (Charley Wingate)\\nSub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>Subject: Re: There must be a creator! (Maybe)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>From: MANDTBACKA@FINABO.ABO.FI (Mats Andtbacka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>From: royc@rbdc.wsnc.org (Roy Crabtree)\\nSubje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>Subject: Re: \"Imaginary\" Friends - Info and Ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            newsgroup                                               text\n",
       "0         alt.atheism  From: mangoe@cs.umd.edu (Charley Wingate)\\nSub...\n",
       "1         alt.atheism  Subject: Re: There must be a creator! (Maybe)\\...\n",
       "2         alt.atheism  From: MANDTBACKA@FINABO.ABO.FI (Mats Andtbacka...\n",
       "3  talk.religion.misc  From: royc@rbdc.wsnc.org (Roy Crabtree)\\nSubje...\n",
       "4  talk.religion.misc  Subject: Re: \"Imaginary\" Friends - Info and Ex..."
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
